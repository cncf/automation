name: Test VM Runner

on:
  workflow_dispatch:
    inputs:
      test_gpu:
        description: 'Test GPU Runner'
        required: false
        type: choice
        options:
        - 'yes'
        - 'no'
        default: 'no'
jobs:
  test-runner:
    strategy:
      matrix:
        #shape: [2cpu-8gb, 4cpu-16gb, 8cpu-32gb, 16cpu-64gb, 24cpu-384gb]
        shape: [2cpu-8gb]
        arch: ["x86-64", "arm64"]
    runs-on: oracle-vm-${{ matrix.shape }}-${{ matrix.arch }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Run uname to verify architecture
        run: |
          uname -a
          lsb_release -a
          id
          cat /etc/group
          cat /proc/cpuinfo

      - name: Run a basic workload
        run: |
          echo "Testing Runner"
          echo "CPU Info:"
          lscpu
          docker run hello-world

      - name: Check local disk 
        run: |
         df -h /

      - name: Run kind cluster
        run: |
          CLUSTER_NAME="kind-test"
          KIND_CONFIG="kind-config.yaml"

          sudo sysctl fs.inotify.max_user_instances=1280
          sudo sysctl fs.inotify.max_user_watches=655360

          cat <<EOF > $KIND_CONFIG
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
            - role: control-plane
            - role: worker
            - role: worker
          EOF

          echo "[*] Creating Kind cluster..."
          kind create cluster --name $CLUSTER_NAME --config $KIND_CONFIG

          kubectl wait --for=condition=Ready nodes --all --timeout=120s

          echo "[*] Creating Kind cluster..."
          kind create cluster --name $CLUSTER_NAME --config $KIND_CONFIG

          kubectl wait --for=condition=Ready nodes --all --timeout=120s

          echo "[*] Creating pod ..."
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: Pod
          metadata:
            name: nginx
          spec:
            containers:
            - name: nginx
              image: nginx:latest
              resources:
                requests:
                  memory: "256Mi"
                  cpu: "100m"
                limits:
                  memory: "256Mi"
                  cpu: "500m"
          EOF

          echo "[*] Waiting for pods to be ready..."
          kubectl wait --for=condition=Ready pod/nginx --timeout=300s

          echo "[*] Pods running, doing test workload..."
          sleep 60

          echo "[*] Deleting pods..."
          kubectl delete pod nginx

          echo "[*] Deleting Kind cluster..."
          kind delete cluster --name $CLUSTER_NAME

          echo "[*] Done!"
  test-gpu-runner:
    runs-on: oracle-vm-gpu-a10-1
    if: ${{ github.event.inputs.test_gpu == 'yes' }}
    steps:
      - name: checkout gpus
        run: |
          echo "[*] Detailed GPU query"
          nvidia-smi -q

          echo "[*] Specific information"
          nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv

          echo "[*] NVIDIA driver version"
          cat /proc/driver/nvidia/version
